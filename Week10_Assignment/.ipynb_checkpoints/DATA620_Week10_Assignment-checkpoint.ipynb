{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA620: Assignment 10 - Document Classification\n",
    "\n",
    "## Homework Team 3: David Simbandumwe, Eric Lehmphul and Lidiia Tronina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data: [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "For more adventurous students, you are welcome to come up a different set of documents that have already been classified , then analyze these documents to predict how new documents should be classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading inagural: Package 'inagural' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lidiiatronina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "from operator import itemgetter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('inagural')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a corpus of interest for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presidentsâ€™ words matter. For better or worse, presidential rhetoric tells the American people who they are. That's why we decided to look at the inaugural speeches from the freely available library that can be downloaded from the NLTK package. The corpus is a collection of 55 texts, one for each presidential address.\n",
    "Let's look at available texts in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt',\n",
       " '2021-Biden.txt']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 59 Presidential inaugural speeches. We want to classify presidential speeches as Republican/Democrat. Most presidents have belonged to one of these two parties (except some who were Whigs and National Union), and we can start as early as Andrew Jackson's 1829 speech. It will be interesting to see if the two parties have different word use in their addresses and if we can identify the president's party by word choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>Washington</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Washington</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Federalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Madison</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>Madison</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>Jackson</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Jackson</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>VanBuren</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>Harrison</td>\n",
       "      <td>Whig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>Polk</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>Whig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>Pierce</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>Buchanan</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       president                party\n",
       "year                                 \n",
       "1789  Washington                 None\n",
       "1793  Washington                 None\n",
       "1797       Adams           Federalist\n",
       "1801   Jefferson  Democrat-Republican\n",
       "1805   Jefferson  Democrat-Republican\n",
       "1809     Madison  Democrat-Republican\n",
       "1813     Madison  Democrat-Republican\n",
       "1817      Monroe  Democrat-Republican\n",
       "1821      Monroe  Democrat-Republican\n",
       "1825       Adams  Democrat-Republican\n",
       "1829     Jackson             Democrat\n",
       "1833     Jackson             Democrat\n",
       "1837    VanBuren             Democrat\n",
       "1841    Harrison                 Whig\n",
       "1845        Polk             Democrat\n",
       "1849      Taylor                 Whig\n",
       "1853      Pierce             Democrat\n",
       "1857    Buchanan             Democrat\n",
       "1861     Lincoln           Republican\n",
       "1865     Lincoln           Republican"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party = pd.read_csv('https://raw.githubusercontent.com/dsimband/DATA620_Group3/main/Week10_Assignment/presidents.csv',index_col=0)\n",
    "\n",
    "party.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 152901 words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152901"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ALL words\n",
    "all_words = inaugural.words()\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Washington's speech\n",
    "inaugural.words('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For text 1985-Reagan.txt, the number of unique words is 876\n",
      "For text 1989-Bush.txt, the number of unique words is 754\n",
      "For text 1993-Clinton.txt, the number of unique words is 604\n",
      "For text 1997-Clinton.txt, the number of unique words is 727\n",
      "For text 2001-Bush.txt, the number of unique words is 593\n",
      "For text 2005-Bush.txt, the number of unique words is 742\n",
      "For text 2009-Obama.txt, the number of unique words is 900\n",
      "For text 2013-Obama.txt, the number of unique words is 792\n",
      "For text 2017-Trump.txt, the number of unique words is 547\n",
      "For text 2021-Biden.txt, the number of unique words is 783\n"
     ]
    }
   ],
   "source": [
    "recent_list = inaugural.fileids()[-10:] \n",
    "for text in recent_list:\n",
    "    word_list = inaugural.words(text)\n",
    "    word_list = [w.lower() for w in word_list]  # handle the case sensitivity\n",
    "    unique_words = len(set(word_list))\n",
    "    print (\"For text \" + text + \", the number of unique words is\", str(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text_data = pd.DataFrame(columns = ['filename','year','length','unique'])\n",
    "for file in inaugural.fileids():\n",
    "    word_list = inaugural.words(file)\n",
    "    word_list = [w.lower() for w in word_list] \n",
    "    this_file = pd.DataFrame(data = {\"filename\":[file], \\\n",
    "                                     \"president\" : [str(file[5:])], \\\n",
    "                                     \"year\" : [int(file[:4])], \\\n",
    "                                     \"length\" : [len(word_list)], \\\n",
    "                                     \"unique\" : [len(set(word_list))]})\n",
    "    text_data = text_data.append(this_file, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>president</th>\n",
       "      <th>unique</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2013-Obama.txt</td>\n",
       "      <td>2369</td>\n",
       "      <td>Obama</td>\n",
       "      <td>792</td>\n",
       "      <td>2013</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2017-Trump.txt</td>\n",
       "      <td>1693</td>\n",
       "      <td>Trump</td>\n",
       "      <td>547</td>\n",
       "      <td>2017</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-Biden.txt</td>\n",
       "      <td>3104</td>\n",
       "      <td>Biden</td>\n",
       "      <td>783</td>\n",
       "      <td>2021</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename length president unique  year       party\n",
       "116  2013-Obama.txt   2369     Obama    792  2013    Democrat\n",
       "117  2017-Trump.txt   1693     Trump    547  2017  Republican\n",
       "118  2021-Biden.txt   3104     Biden    783  2021    Democrat"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data['president'] = text_data['president'].str.replace('.txt','')\n",
    "president_party = pd.merge(text_data, party, on='president', how='outer')\n",
    "\n",
    "president_party[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to take all Democrat/Republican speeches and combine them to create one text. We will also remove punctuation and convert everything to lowercase to eliminate duplicate words. Then we can take that and create a list of text segments. Each segment will have a length of 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat = inaugural.words('1833-Jackson.txt')+inaugural.words('1837-VanBuren.txt')+inaugural.words('1845-Polk.txt')+inaugural.words('1853-Pierce.txt')+inaugural.words('1857-Buchanan.txt')+inaugural.words('1885-Cleveland.txt')+inaugural.words('1893-Cleveland.txt')+inaugural.words('1905-Roosevelt.txt')+inaugural.words('1933-Roosevelt.txt')+inaugural.words('1937-Roosevelt.txt')+inaugural.words('1941-Roosevelt.txt')+inaugural.words('1945-Roosevelt.txt')+inaugural.words('1913-Wilson.txt')+inaugural.words('1917-Wilson.txt')+inaugural.words('1949-Truman.txt')+inaugural.words('1961-Kennedy.txt')+inaugural.words('1965-Johnson.txt')+inaugural.words('1969-Nixon.txt')+inaugural.words('1973-Nixon.txt')+inaugural.words('1977-Carter.txt')+inaugural.words('1993-Clinton.txt')+inaugural.words('1997-Clinton.txt')+inaugural.words('2009-Obama.txt')+inaugural.words('2013-Obama.txt')+inaugural.words('2021-Biden.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican = inaugural.words('1841-Harrison.txt')+inaugural.words('1889-Harrison.txt')+inaugural.words('1861-Lincoln.txt')+inaugural.words('1865-Lincoln.txt')+inaugural.words('1869-Grant.txt')+inaugural.words('1873-Grant.txt')+inaugural.words('1877-Hayes.txt')+inaugural.words('1881-Garfield.txt')+inaugural.words('1897-McKinley.txt')+inaugural.words('1901-McKinley.txt')+inaugural.words('1905-Roosevelt.txt')+inaugural.words('1933-Roosevelt.txt')+inaugural.words('1937-Roosevelt.txt')+inaugural.words('1941-Roosevelt.txt')+inaugural.words('1945-Roosevelt.txt')+inaugural.words('1909-Taft.txt')+inaugural.words('1921-Harding.txt')+inaugural.words('1925-Coolidge.txt')+inaugural.words('1929-Hoover.txt')+inaugural.words('1953-Eisenhower.txt')+inaugural.words('1957-Eisenhower.txt')+inaugural.words('1969-Nixon.txt')+inaugural.words('1973-Nixon.txt')+inaugural.words('1981-Reagan.txt')+inaugural.words('1985-Reagan.txt')+inaugural.words('1989-Bush.txt')+inaugural.words('2001-Bush.txt')+inaugural.words('2005-Bush.txt')+inaugural.words('2017-Trump.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "#remove punctuation\n",
    "custom_stopwords = set((',',' ','.', ';', '?', '-', '!', '(', ')','--','\"',\"'\", ':', 'Â¡Â¦', 'Â¡','Â€Â”', '9', '/', '11','ii', '400','1863','','people','shall','may','country','government','world', 'nation', 'must', 'great','upon','america','new','one','states','peace','every','us',',\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_filtered = [word.lower() for word in democrat if word.lower() not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_filtered2 = [ word.lower() for word in dem_filtered if word.lower() not in custom_stopwords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21901"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dem_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat1=[]\n",
    "for i in range(43):\n",
    "    democrat1.append([dem_filtered2[i*500:(i+1)*500],'dem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(democrat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_filtered = [word.lower() for word in republican if word.lower() not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_filtered2 = [ word.lower() for word in rep_filtered if word.lower() not in custom_stopwords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32344"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rep_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican1=[]\n",
    "for i in range(64):\n",
    "    republican1.append([rep_filtered2[i*500:(i+1)*500],'rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(republican1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of 24 Democrat and 35 Republican 1000-word segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('let', 109),\n",
       " ('time', 102),\n",
       " ('power', 90),\n",
       " ('nations', 78),\n",
       " ('life', 78),\n",
       " ('union', 74),\n",
       " ('american', 73),\n",
       " ('citizens', 72),\n",
       " ('would', 72),\n",
       " ('spirit', 72),\n",
       " ('today', 70),\n",
       " ('united', 69),\n",
       " ('men', 69),\n",
       " ('free', 68),\n",
       " ('fellow', 65),\n",
       " ('together', 65),\n",
       " ('know', 63),\n",
       " ('constitution', 62),\n",
       " ('work', 60),\n",
       " ('public', 59)]"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(dem_filtered2)\n",
    "fdist.most_common(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('freedom', 132),\n",
       " ('power', 129),\n",
       " ('citizens', 119),\n",
       " ('constitution', 116),\n",
       " ('time', 112),\n",
       " ('would', 111),\n",
       " ('law', 107),\n",
       " ('free', 106),\n",
       " ('make', 104),\n",
       " ('public', 103),\n",
       " ('american', 99),\n",
       " ('united', 96),\n",
       " ('congress', 93),\n",
       " ('made', 92),\n",
       " ('years', 92),\n",
       " ('nations', 92),\n",
       " ('war', 90),\n",
       " ('national', 88),\n",
       " ('men', 86),\n",
       " ('good', 85)]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1 = nltk.FreqDist(rep_filtered2)\n",
    "fdist1.most_common(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=dem_filtered2+rep_filtered2\n",
    "all_words = nltk.FreqDist(w.lower() for w in all)\n",
    "word_features = list(all_words)[:2000] \n",
    "\n",
    "wlist = []\n",
    "for i in range(0, 2000, 200):\n",
    "    df = pd.DataFrame(word_features[i:(i+200)])\n",
    "    df.columns=['200 words']\n",
    "    wlist.append(df)\n",
    "\n",
    "#pd.concat(wlist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contains(fellow)', True),\n",
       " ('contains(citizens)', True),\n",
       " ('contains(american)', True),\n",
       " ('contains(expressed)', True),\n",
       " ('contains(unsolicited)', True),\n",
       " ('contains(suffrages)', True),\n",
       " ('contains(calls)', True),\n",
       " ('contains(pass)', True),\n",
       " ('contains(solemnities)', True),\n",
       " ('contains(preparatory)', True),\n",
       " ('contains(taking)', True),\n",
       " ('contains(duties)', True),\n",
       " ('contains(president)', True),\n",
       " ('contains(united)', True),\n",
       " ('contains(another)', True),\n",
       " ('contains(term)', True),\n",
       " ('contains(approbation)', True),\n",
       " ('contains(public)', True),\n",
       " ('contains(conduct)', True),\n",
       " ('contains(period)', True)]"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = document_features(dem_filtered2)\n",
    "list(features.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=republican1+democrat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.2)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(gave) = True              dem : rep    =      7.1 : 1.0\n",
      "        contains(actual) = True              dem : rep    =      7.1 : 1.0\n",
      "         contains(globe) = True              dem : rep    =      7.1 : 1.0\n",
      "     contains(diversity) = True              dem : rep    =      5.4 : 1.0\n",
      "  contains(achievements) = True              dem : rep    =      5.4 : 1.0\n",
      "      contains(honestly) = True              dem : rep    =      5.4 : 1.0\n",
      "          contains(calm) = True              dem : rep    =      4.6 : 1.0\n",
      "       contains(hostile) = True              dem : rep    =      4.6 : 1.0\n",
      "        contains(forget) = True              dem : rep    =      4.6 : 1.0\n",
      "        contains(uphold) = True              dem : rep    =      4.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features_in_list(classifier, n=10):\n",
    "    \"\"\"\n",
    "    Return a nested list of the \"most informative\" features \n",
    "    used by the classifier along with it's predominant labels\n",
    "    \"\"\"\n",
    "    cpdist = classifier._feature_probdist       # probability distribution for feature values given labels\n",
    "    feature_list = []\n",
    "    for (fname, fval) in classifier.most_informative_features(n):\n",
    "        def labelprob(l):\n",
    "            return cpdist[l, fname].prob(fval)\n",
    "        labels = sorted([l for l in classifier._labels if fval in cpdist[l, fname].samples()], \n",
    "                        key=labelprob)\n",
    "        feature_list.append([fname, labels[-1]])\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['contains(fruitful)', 'dem'],\n",
       " ['contains(compromise)', 'dem'],\n",
       " ['contains(appropriate)', 'dem'],\n",
       " ['contains(minds)', 'dem'],\n",
       " ['contains(concession)', 'dem'],\n",
       " ['contains(excited)', 'dem'],\n",
       " ['contains(opened)', 'dem'],\n",
       " ['contains(achievements)', 'dem'],\n",
       " ['contains(eyes)', 'dem'],\n",
       " ['contains(conferred)', 'dem']]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_most_informative_features_in_list(classifier,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
