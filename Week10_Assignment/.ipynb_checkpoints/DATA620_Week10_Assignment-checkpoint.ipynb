{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA620: Assignment 10 - Document Classification\n",
    "\n",
    "## Homework Team 3: David Simbandumwe, Eric Lehmphul and Lidiia Tronina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data: [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "For more adventurous students, you are welcome to come up a different set of documents that have already been classified , then analyze these documents to predict how new documents should be classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading inagural: Package 'inagural' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lidiiatronina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "from operator import itemgetter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('inagural')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a corpus of interest for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presidentsâ€™ words matter. For better or worse, presidential rhetoric tells the American people who they are. That's why we decided to look at the inaugural speeches from the freely available library that can be downloaded from the NLTK package. The corpus is a collection of 55 texts, one for each presidential address.\n",
    "\n",
    "We want to classify presidential speeches as Republican/Democrat. Most presidents have belonged to one of these two parties (except some who were Whigs and National Union), and we can start as early as Andrew Jackson's 1829 speech. It will be interesting to see if the two parties have different word use in their addresses and if we can identify the president's party by word choices.\n",
    "\n",
    "Let's look at available texts in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt',\n",
       " '2021-Biden.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>Washington</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Washington</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Federalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Madison</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>Madison</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Democrat-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>Jackson</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Jackson</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>VanBuren</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>Harrison</td>\n",
       "      <td>Whig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>Polk</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>Whig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>Pierce</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>Buchanan</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       president                party\n",
       "year                                 \n",
       "1789  Washington                 None\n",
       "1793  Washington                 None\n",
       "1797       Adams           Federalist\n",
       "1801   Jefferson  Democrat-Republican\n",
       "1805   Jefferson  Democrat-Republican\n",
       "1809     Madison  Democrat-Republican\n",
       "1813     Madison  Democrat-Republican\n",
       "1817      Monroe  Democrat-Republican\n",
       "1821      Monroe  Democrat-Republican\n",
       "1825       Adams  Democrat-Republican\n",
       "1829     Jackson             Democrat\n",
       "1833     Jackson             Democrat\n",
       "1837    VanBuren             Democrat\n",
       "1841    Harrison                 Whig\n",
       "1845        Polk             Democrat\n",
       "1849      Taylor                 Whig\n",
       "1853      Pierce             Democrat\n",
       "1857    Buchanan             Democrat\n",
       "1861     Lincoln           Republican\n",
       "1865     Lincoln           Republican"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party = pd.read_csv('https://raw.githubusercontent.com/dsimband/DATA620_Group3/main/Week10_Assignment/presidents.csv',index_col=0)\n",
    "\n",
    "party.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 152901 words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152901"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ALL words\n",
    "all_words = inaugural.words()\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Washington's speech\n",
    "inaugural.words('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For text 1985-Reagan.txt, the number of unique words is 876\n",
      "For text 1989-Bush.txt, the number of unique words is 754\n",
      "For text 1993-Clinton.txt, the number of unique words is 604\n",
      "For text 1997-Clinton.txt, the number of unique words is 727\n",
      "For text 2001-Bush.txt, the number of unique words is 593\n",
      "For text 2005-Bush.txt, the number of unique words is 742\n",
      "For text 2009-Obama.txt, the number of unique words is 900\n",
      "For text 2013-Obama.txt, the number of unique words is 792\n",
      "For text 2017-Trump.txt, the number of unique words is 547\n",
      "For text 2021-Biden.txt, the number of unique words is 783\n"
     ]
    }
   ],
   "source": [
    "recent_list = inaugural.fileids()[-10:] \n",
    "for text in recent_list:\n",
    "    word_list = inaugural.words(text)\n",
    "    word_list = [w.lower() for w in word_list]  # handle the case sensitivity\n",
    "    unique_words = len(set(word_list))\n",
    "    print (\"For text \" + text + \", the number of unique words is\", str(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text_data = pd.DataFrame(columns = ['filename','year','length','unique'])\n",
    "for file in inaugural.fileids():\n",
    "    word_list = inaugural.words(file)\n",
    "    word_list = [w.lower() for w in word_list] \n",
    "    this_file = pd.DataFrame(data = {\"filename\":[file], \\\n",
    "                                     \"president\" : [str(file[5:])], \\\n",
    "                                     \"year\" : [int(file[:4])], \\\n",
    "                                     \"length\" : [len(word_list)], \\\n",
    "                                     \"unique\" : [len(set(word_list))]})\n",
    "    text_data = text_data.append(this_file, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>president</th>\n",
       "      <th>unique</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2013-Obama.txt</td>\n",
       "      <td>2369</td>\n",
       "      <td>Obama</td>\n",
       "      <td>792</td>\n",
       "      <td>2013</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2017-Trump.txt</td>\n",
       "      <td>1693</td>\n",
       "      <td>Trump</td>\n",
       "      <td>547</td>\n",
       "      <td>2017</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-Biden.txt</td>\n",
       "      <td>3104</td>\n",
       "      <td>Biden</td>\n",
       "      <td>783</td>\n",
       "      <td>2021</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename length president unique  year       party\n",
       "116  2013-Obama.txt   2369     Obama    792  2013    Democrat\n",
       "117  2017-Trump.txt   1693     Trump    547  2017  Republican\n",
       "118  2021-Biden.txt   3104     Biden    783  2021    Democrat"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data['president'] = text_data['president'].str.replace('.txt','')\n",
    "president_party = pd.merge(text_data, party, on='president', how='outer')\n",
    "\n",
    "president_party[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Documents for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to take all Democrat/Republican speeches and combine them to create one text. We will also remove punctuation and convert everything to lowercase to eliminate duplicate words. \n",
    "We also want to remove some of the common words for both parties such as - people, nation, world, country, etc.\n",
    "Then we can take that and create a list of text segments. Each segment will be 500 words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat = inaugural.words('1833-Jackson.txt')+inaugural.words('1837-VanBuren.txt')+inaugural.words('1845-Polk.txt')+inaugural.words('1853-Pierce.txt')+inaugural.words('1857-Buchanan.txt')+inaugural.words('1885-Cleveland.txt')+inaugural.words('1893-Cleveland.txt')+inaugural.words('1905-Roosevelt.txt')+inaugural.words('1933-Roosevelt.txt')+inaugural.words('1937-Roosevelt.txt')+inaugural.words('1941-Roosevelt.txt')+inaugural.words('1945-Roosevelt.txt')+inaugural.words('1913-Wilson.txt')+inaugural.words('1917-Wilson.txt')+inaugural.words('1949-Truman.txt')+inaugural.words('1961-Kennedy.txt')+inaugural.words('1965-Johnson.txt')+inaugural.words('1969-Nixon.txt')+inaugural.words('1973-Nixon.txt')+inaugural.words('1977-Carter.txt')+inaugural.words('1993-Clinton.txt')+inaugural.words('1997-Clinton.txt')+inaugural.words('2009-Obama.txt')+inaugural.words('2013-Obama.txt')+inaugural.words('2021-Biden.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican = inaugural.words('1841-Harrison.txt')+inaugural.words('1889-Harrison.txt')+inaugural.words('1861-Lincoln.txt')+inaugural.words('1865-Lincoln.txt')+inaugural.words('1869-Grant.txt')+inaugural.words('1873-Grant.txt')+inaugural.words('1877-Hayes.txt')+inaugural.words('1881-Garfield.txt')+inaugural.words('1897-McKinley.txt')+inaugural.words('1901-McKinley.txt')+inaugural.words('1905-Roosevelt.txt')+inaugural.words('1933-Roosevelt.txt')+inaugural.words('1937-Roosevelt.txt')+inaugural.words('1941-Roosevelt.txt')+inaugural.words('1945-Roosevelt.txt')+inaugural.words('1909-Taft.txt')+inaugural.words('1921-Harding.txt')+inaugural.words('1925-Coolidge.txt')+inaugural.words('1929-Hoover.txt')+inaugural.words('1953-Eisenhower.txt')+inaugural.words('1957-Eisenhower.txt')+inaugural.words('1969-Nixon.txt')+inaugural.words('1973-Nixon.txt')+inaugural.words('1981-Reagan.txt')+inaugural.words('1985-Reagan.txt')+inaugural.words('1989-Bush.txt')+inaugural.words('2001-Bush.txt')+inaugural.words('2005-Bush.txt')+inaugural.words('2017-Trump.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "#remove punctuation and common words\n",
    "custom_stopwords = set((',',' ','.', ';', '?', '-', '!', '(', ')','--','\"',\"'\", ':', 'Â¡Â¦', 'Â¡','Â€Â”', '9', '/', '11','ii', '400','1863','','people','shall','may','country','government','world', 'nation', 'must', 'great','upon','america','new','one','states','peace','every','us',',\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_filtered = [word.lower() for word in democrat if word.lower() not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_filtered2 = [ word.lower() for word in dem_filtered if word.lower() not in custom_stopwords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21901"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dem_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat1=[]\n",
    "for i in range(43):\n",
    "    democrat1.append([dem_filtered2[i*500:(i+1)*500],'dem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(democrat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_filtered = [word.lower() for word in republican if word.lower() not in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_filtered2 = [ word.lower() for word in rep_filtered if word.lower() not in custom_stopwords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32344"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rep_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican1=[]\n",
    "for i in range(64):\n",
    "    republican1.append([rep_filtered2[i*500:(i+1)*500],'rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(republican1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of 43 Democrat and 64 Republican 500-word segments. These are the most common words for each party:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('let', 109),\n",
       " ('time', 102),\n",
       " ('power', 90),\n",
       " ('nations', 78),\n",
       " ('life', 78),\n",
       " ('union', 74),\n",
       " ('american', 73),\n",
       " ('citizens', 72),\n",
       " ('would', 72),\n",
       " ('spirit', 72),\n",
       " ('today', 70),\n",
       " ('united', 69),\n",
       " ('men', 69),\n",
       " ('free', 68),\n",
       " ('fellow', 65),\n",
       " ('together', 65),\n",
       " ('know', 63),\n",
       " ('constitution', 62),\n",
       " ('work', 60),\n",
       " ('public', 59)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(dem_filtered2)\n",
    "fdist.most_common(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('freedom', 132),\n",
       " ('power', 129),\n",
       " ('citizens', 119),\n",
       " ('constitution', 116),\n",
       " ('time', 112),\n",
       " ('would', 111),\n",
       " ('law', 107),\n",
       " ('free', 106),\n",
       " ('make', 104),\n",
       " ('public', 103),\n",
       " ('american', 99),\n",
       " ('united', 96),\n",
       " ('congress', 93),\n",
       " ('made', 92),\n",
       " ('years', 92),\n",
       " ('nations', 92),\n",
       " ('war', 90),\n",
       " ('national', 88),\n",
       " ('men', 86),\n",
       " ('good', 85)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1 = nltk.FreqDist(rep_filtered2)\n",
    "fdist1.most_common(20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a method from Natural Language Processing with Python to define a feature extractor for documents, so the classifier will know which aspects of the data it should pay attention to. We can define a feature for each word, indicating whether the segment contains that word. To limit the number of features that the classifier needs to process, we begin by constructing a list of the 2000 most frequent words in the overall corpus. We can then define a feature extractor that simply checks whether each of these words is present in a given document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=dem_filtered2+rep_filtered2\n",
    "all_words = nltk.FreqDist(w.lower() for w in all)\n",
    "word_features = list(all_words)[:2000] \n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contains(fellow)', True),\n",
       " ('contains(citizens)', True),\n",
       " ('contains(american)', True),\n",
       " ('contains(expressed)', True),\n",
       " ('contains(unsolicited)', True),\n",
       " ('contains(suffrages)', True),\n",
       " ('contains(calls)', True),\n",
       " ('contains(pass)', True),\n",
       " ('contains(solemnities)', True),\n",
       " ('contains(preparatory)', True),\n",
       " ('contains(taking)', True),\n",
       " ('contains(duties)', True),\n",
       " ('contains(president)', True),\n",
       " ('contains(united)', True),\n",
       " ('contains(another)', True),\n",
       " ('contains(term)', True),\n",
       " ('contains(approbation)', True),\n",
       " ('contains(public)', True),\n",
       " ('contains(conduct)', True),\n",
       " ('contains(period)', True)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = document_features(dem_filtered2)\n",
    "list(features.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our feature extractor, we can use it to train a classifier to label each speech segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=republican1+democrat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test and Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a list of all text segments from both Republican and Democrat and shuffle them to create the text corpus that we will use to train and test our classifier model. We will use 86 segments to train our model and leave 21 segments for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random.seed(123)\n",
    "random.shuffle(documents)\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.2)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use naive Bayes classifier to train our first model. To choose a label for an input value, the naive Bayes classifier begins by calculating the prior probability of each label, which is determined by checking frequency of each label in the training set. The contribution from each feature is then combined with this prior probability, to arrive at a likelihood estimate for each label. \n",
    "(Natural Language Processing with Python https://www.nltk.org/book/ch06.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a 66,6% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features are most important in training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(concession) = True              dem : rep    =      8.7 : 1.0\n",
      "        contains(actual) = True              dem : rep    =      7.8 : 1.0\n",
      "    contains(protecting) = True              dem : rep    =      7.8 : 1.0\n",
      "         contains(minds) = True              dem : rep    =      6.9 : 1.0\n",
      "      contains(fruitful) = True              dem : rep    =      6.0 : 1.0\n",
      " contains(consciousness) = True              dem : rep    =      6.0 : 1.0\n",
      "   contains(appropriate) = True              dem : rep    =      6.0 : 1.0\n",
      "         contains(globe) = True              dem : rep    =      6.0 : 1.0\n",
      "         contains(happy) = True              dem : rep    =      5.8 : 1.0\n",
      "        contains(humbly) = True              dem : rep    =      5.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, the most informative of the party words for democrats are concession, protecting, fruitful, consciosness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
