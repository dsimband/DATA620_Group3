{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925f984b",
   "metadata": {},
   "source": [
    "# DATA620: Project 3 - Gender Identification\n",
    "\n",
    "## Homework Team 3: David Simbandumwe, Eric Lehmphul and Lidiia Tronina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2419732",
   "metadata": {},
   "source": [
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "<br>\n",
    "We chose to use the NaiveBayesClassifier machine learning method to categorize the names Corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9bb7cc",
   "metadata": {},
   "source": [
    "### Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5300358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e72991-3f54-4509-8fa2-c6d60f17a347",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "### Model Base Class\n",
    "This is a Generic class with base model and boiler plate analysis code. It is used to simplify the analysis for each subsequent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cf75c-98dd-4b99-8dbc-25e1f710a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generic class with base model\n",
    "class GenderAnalysis():\n",
    "    \n",
    "    # set corpus and training datasets\n",
    "    def __init__(self):\n",
    "       \n",
    "        random.seed(3210)\n",
    "        self._classifier = None\n",
    "        \n",
    "        # Import and Lable Names\n",
    "        self._names_lst = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                [(name, 'female') for name in names.words('female.txt')])\n",
    "        random.shuffle(self._names_lst)\n",
    "\n",
    "        # Split Corpus\n",
    "        self._train_names = self._names_lst[1000:]\n",
    "        self._devtest_names = self._names_lst[500:1000]\n",
    "        self._test_names = self._names_lst[:500]\n",
    "    \n",
    "        # apply features training, devtest and test corpus\n",
    "        self._train_set = apply_features(self.gender_features, self._train_names)\n",
    "        self._devtest_set = apply_features(self.gender_features, self._devtest_names)\n",
    "        self._test_set = apply_features(self.gender_features, self._test_names)          \n",
    "\n",
    " \n",
    "    # generate features\n",
    "    def gender_features(self, name):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # get features dataframe \n",
    "    def get_names_features(self):\n",
    "        # analyze data\n",
    "        df = pd.DataFrame(self._names_lst, columns=['name','gender'])\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    # get names that can be both male and female\n",
    "    def ambiguous_names(self):\n",
    "        # analyze data\n",
    "        df = pd.DataFrame(self._names_lst, columns=['name','gender'])\n",
    "        df2 = df.groupby(['name'])['name'].count().reset_index(name='count').sort_values(\n",
    "            ['count'], ascending=False)\n",
    "        df2 = df2[df2['count']>1]\n",
    "        name_df = pd.merge(df,df2,how=\"inner\", on=[\"name\"])\n",
    "        \n",
    "        #name_df = name_df.drop('count', 1)\n",
    "        name_df = name_df[['name']]\n",
    "        name_df = name_df.groupby('name').first().reset_index()\n",
    "        \n",
    "        return name_df\n",
    "    \n",
    "    \n",
    "    # train the model\n",
    "    def train(self):\n",
    "        self._classifier = nltk.NaiveBayesClassifier.train(self._train_set)\n",
    "        \n",
    "        \n",
    "    # return the accuracy of the dev test\n",
    "    def get_devtest_accuracy(self):     \n",
    "        return nltk.classify.accuracy(self._classifier, self._devtest_set)\n",
    "        \n",
    "\n",
    "    # return the features with the biggest impact\n",
    "    def show_inform_feature(self, n=20):\n",
    "        self._classifier.show_most_informative_features(n)\n",
    "        \n",
    "    \n",
    "    # return a dataframe with the errors\n",
    "    def get_errors(self):\n",
    "        errors = []\n",
    "        for (name, tag) in self._devtest_names:\n",
    "            guess = self._classifier.classify(self.gender_features(name))\n",
    "            if guess != tag:\n",
    "                errors.append((tag, guess, name))                \n",
    "          \n",
    "        errors_df = pd.DataFrame(errors, columns=['tag', 'guess', 'name'])\n",
    "        return errors_df\n",
    "    \n",
    "    \n",
    "    # print the model errors\n",
    "    def print_Errors(self):\n",
    "        for (tag, guess, name) in sorted(errors):\n",
    "            print ('correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))\n",
    "\n",
    "     \n",
    "    # print the errors that are driven by Unisex names\n",
    "    def get_ambiguous_errors(self):\n",
    "        df1 = self.ambiguous_names()\n",
    "        df2 = self.get_errors()\n",
    "        error_df = pd.merge(df1,df2,how=\"inner\", on=[\"name\"])\n",
    "        return error_df\n",
    "    \n",
    "    \n",
    "    # determint the accuracy of the model using test data\n",
    "    def get_test_accuracy(self):\n",
    "        return nltk.classify.accuracy(self._classifier, self._test_set)\n",
    "    \n",
    "    # explore of error records\n",
    "    def get_error_stats(self):\n",
    "              \n",
    "        df = self.get_errors()\n",
    "        \n",
    "        df['length'] = df['name'].str.len()\n",
    "        df['last_letter'] = df['name'].str[-1]\n",
    "        df['first_letter'] = df['name'].str[0]\n",
    "\n",
    "        df['vowels'] = df['name'].str.replace(r'[^aeiou]', '', regex=True)\n",
    "        df['vowel_last_letter'] = df['last_letter'].isin([*'aeiouy'])\n",
    "        df['vowel_first_letter'] = df['first_letter'].isin([*'AEIOUY'])\n",
    "\n",
    "        df['consonants'] = df['name'].str.replace(r'[aeiou]', '', regex=True)\n",
    "        df['consonant_last_letter'] = df['last_letter'].isin([*'qwrtplkjhgfdszxcvbnm'])\n",
    "        df['consonant_first_letter'] = df['first_letter'].isin([*'QWRTPLKJHGFDSZXCVBNM'])\n",
    "\n",
    "        df['num_vowels'] = df['vowels'].str.len()\n",
    "        df['num_consonants'] = df['consonants'].str.len()\n",
    "        \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba5203-f7d8-4899-a24a-3bfdbe5a6ac4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### K-Fold Sub Class\n",
    "The K-Fold sub class adds a method to the generic class that genereates test stats for the k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb65aba-b9a1-4209-a475-68dcc08acaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic class with base model\n",
    "class GenderAnalysisKFold(GenderAnalysis):\n",
    "\n",
    "       \n",
    "    # get kfold\n",
    "    def get_kfold(self, n=10):\n",
    "        \n",
    "        cross_val_names = self._names_lst[500:]\n",
    "\n",
    "        kf = KFold(n_splits=n)\n",
    "        variables = apply_features(self.gender_features, cross_val_names)\n",
    "        \n",
    "        \n",
    "        test_accuracy = {}\n",
    "        sum = 0\n",
    "        i = 1\n",
    "        for train, test in kf.split(variables):\n",
    "            train_data = np.array(variables)[train]\n",
    "            test_data = np.array(variables)[test]\n",
    "            classifier = nltk.NaiveBayesClassifier.train(train_data)\n",
    "            test_accuracy.update({'k_'+str(i):round(nltk.classify.accuracy(classifier, test_data),3)})           \n",
    "            i += 1\n",
    "        \n",
    "        test_accuracy.update({'k_average':round(mean(test_accuracy.values()),3)})        \n",
    "        return pd.DataFrame([test_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008f1c6-e917-4a5f-a38a-5f92e35db9c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model Sub-classes\n",
    "Each Model class inherits from the GenderAnalusis base class. The key difference between each subclass is the implimention of the gender_features()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e79fea-47a8-48dd-afad-6efea0f0cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uses the last letters as features \n",
    "class GenderAnalysis1(GenderAnalysisKFold):\n",
    "    \n",
    "    def gender_features(self, name):\n",
    "        features = {}\n",
    "        features[\"suffix1\"] = name[-1].lower()\n",
    "        return features\n",
    "\n",
    "\n",
    "\n",
    "# Uses the last 2 letters as features \n",
    "class GenderAnalysis2(GenderAnalysisKFold):\n",
    "    \n",
    "    def gender_features(self, name):\n",
    "        features = {}\n",
    "        features[\"suffix1\"] = name[-1].lower()\n",
    "        features[\"suffixLast2\"] = name[-2:].lower()\n",
    "\n",
    "        return features\n",
    "\n",
    "    \n",
    "# Use the last 2 letter and the first letter as features\n",
    "class GenderAnalysis3(GenderAnalysisKFold):\n",
    "    \n",
    "    def gender_features(self, name):\n",
    "        features = {}\n",
    "        features[\"firstLetter\"] = name[0].lower()\n",
    "        features[\"suffix1\"] = name[-1].lower()\n",
    "        features[\"suffixLast2\"] = name[-2:].lower()\n",
    "\n",
    "        return features\n",
    "    \n",
    "\n",
    "# Add the vowels as first and last charater and vowel count \n",
    "class GenderAnalysis4(GenderAnalysisKFold):\n",
    "    \n",
    "    \n",
    "    def gender_features(self, name):\n",
    "        features = {}\n",
    "        features[\"length\"] = len(name)\n",
    "        features[\"firstLetter\"] = name[0].lower()\n",
    "        features[\"lastLetter\"] = name[-1].lower()\n",
    "        features[\"firstVowel\"] = features['firstLetter'] in 'aeiouy'\n",
    "        features[\"lastVowel\"] = features['lastLetter'] in 'aeiouy'\n",
    "\n",
    "        # Gets num of vowels\n",
    "        count = 0\n",
    "        vowel = set(\"aeiouAEIOU\")\n",
    "\n",
    "        for i in name:\n",
    "            if i in vowel:\n",
    "                count = count + 1\n",
    "\n",
    "        features[\"numVowels\"] = count\n",
    "        features[\"suffixLast2\"] = name[-2:].lower()\n",
    "        features[\"suffixLast3\"] = name[-3:].lower()\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21549b52-8eb1-4386-944f-3250cfbcee00",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Analysis of Names Corpus\n",
    "The corpus includes 365 Unisex names that have both male and female records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c215b66-3da3-4a9f-b476-cfd5d0a5756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga1 = GenderAnalysis1()\n",
    "ga1.train()\n",
    "\n",
    "# Use the venn2 function\n",
    "df = ga1.get_names_features()\n",
    "s1 = set(df[df['gender'] == 'male']['name'])\n",
    "s2 = set(df[df['gender'] == 'female']['name'])\n",
    "venn2([s1, s2], set_labels = ('male', 'female'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060264b4-32e5-4726-bcf7-aec8cd3f8b8d",
   "metadata": {},
   "source": [
    "This Venn diagram captures that overlap of unisex names between the male and female populations. Interestingly enough there are many more female names in the corpus than male names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03ab31-fe73-46ec-9331-bcf41eb12231",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "### Further Exploration of Names Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c131590-da5a-4dbe-83c7-850c3547a1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explore data further\n",
    "df['length'] = df['name'].str.len()\n",
    "df['last_letter'] = df['name'].str[-1]\n",
    "df['first_letter'] = df['name'].str[0]\n",
    "\n",
    "df['vowels'] = df['name'].str.replace(r'[^aeiouyAEIOUY]', '', regex=True)\n",
    "df['vowel_last_letter'] = df['last_letter'].isin([*'aeiouy'])\n",
    "df['vowel_first_letter'] = df['first_letter'].isin([*'AEIOUY'])\n",
    "\n",
    "df['consonants'] = df['name'].str.replace(r'[aeiouyAEIOUY]', '', regex=True)\n",
    "df['consonant_last_letter'] = df['last_letter'].isin([*'qwrtplkjhgfdszxcvbnm'])\n",
    "df['consonant_first_letter'] = df['first_letter'].isin([*'QWRTPLKJHGFDSZXCVBNM'])\n",
    "\n",
    "df['num_vowels'] = df['vowels'].str.len()\n",
    "df['num_consonants'] = df['consonants'].str.len()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b39bef-82b5-4489-99c8-d6a970d12e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('gender').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46681edf-746e-4a1b-b821-691dc91ec55a",
   "metadata": {},
   "source": [
    "Notable differences between groups in the corpus:\n",
    "* Female names tend to be longer\n",
    "* Female names are much more likely to contain a vowel as the last letter\n",
    "* Female names are slightly more likely to have a vowel as a first letter\n",
    "* Males are much more likely to have a consonant for a last letter\n",
    "* Both groups are almost equally likely to have a consonant as a first letter\n",
    "* Females have more vowels on average\n",
    "* Males have more consonants on average\n",
    "\n",
    "This information provides us with a strong baseline for features to use in our gender name classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31245592-322f-4272-aee5-007045260221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size Train Set',len(ga1._train_names))\n",
    "print('Size Development Set',len(ga1._devtest_names))\n",
    "print('Size Test Set',len(ga1._test_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940c25b-f15d-48cc-bb4a-ee8cfab1412d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model 1\n",
    "This is a simple model the looks at the last character of a name to determine the associated gender. This model has a 80% accuracy if we use 3210 as the seed. We can also count the number of errors that are driven by unisex names. With Model 1 there are 27 errors that can be attributed to unisex names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bb5e3-b76a-4990-bed4-56138fcb298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga1 = GenderAnalysis1()\n",
    "ga1.train()\n",
    "print('devtest accuracy:', ga1.get_devtest_accuracy())\n",
    "print('ambiguous errors:',len(ga1.get_ambiguous_errors()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795e7e7-dcab-4b62-aef0-c6c30791c6a9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The feature list below identifies the features that have the biggest impact on the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d79f2-80f3-4370-b6ab-30a11cc06c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga1.show_inform_feature(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55e2a5-81ca-44f0-ba43-44eea83b1113",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The table below summarizes the default model performance for each last letter. The accuracy levels and the resulting number of errors are high for:\n",
    "* n - all names that end with n are classified as male\n",
    "* e - all names that end in e are classified female\n",
    "* y - all names that end in y are classified female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b149957-72f8-4ff5-90c7-f86ab5a6b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of names in devtest that end with each letter\n",
    "n_df = pd.DataFrame(ga1._devtest_names, columns=['name','gender'])\n",
    "n_df['last_letter'] = n_df['name'].str[-1]\n",
    "n_df = n_df.groupby(['last_letter'])['last_letter'].count().reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "\n",
    "# calculate the errors\n",
    "e_df = ga1.get_errors()\n",
    "e_df['last_letter'] = e_df['name'].str[-1]\n",
    "e_df = e_df.groupby(['last_letter'])['last_letter'].count().reset_index(name='error_count')\n",
    "\n",
    "# merge the dataframes\n",
    "n_df = pd.merge(n_df,e_df,how=\"inner\", on=[\"last_letter\"])\n",
    "n_df['accuracy'] = round(1 - n_df['error_count'] / n_df['count'],3)\n",
    "\n",
    "# calculate the model accuracy for each letter\n",
    "n_df.sort_values(['error_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb32b10-c049-4e78-b772-6390024361fa",
   "metadata": {},
   "source": [
    " <br>\n",
    "\n",
    "### Model 2\n",
    "\n",
    "This model extends the simple model and uses the last letter and the last 2 letters as features for name categorization. This model has a 82.8% accuracy if we use 3210 as the seed. We can also count the number of errors that are driven by unisex names. With Model 2 there are 21 errors that can be attributed to unisex names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222b22c-c04e-49cd-99f9-0bfc5e5dd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga2 = GenderAnalysis2()\n",
    "ga2.train()\n",
    "print('devtest accuracy:', ga2.get_devtest_accuracy())\n",
    "print('ambiguous errors:',len(ga2.get_ambiguous_errors()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f728c5-b356-41bd-9caf-6028cd708486",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The feature list below identifies the features that have the biggest impact on the model. It should be noted that suffixLast2 features dominate the top features list. Indicating that using 2 of the last characters is more deterministic of gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aef123-5586-42ab-ad8c-49ee3eba1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga2.show_inform_feature(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8447ec7-4579-449b-9712-a406615e0901",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The errors in name gender categorization are summarized in the following data frame. It is difficult to identify patterns at the individual name level so we will run some sample stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa5858-dd11-4e52-88ab-7a9103196f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga2.get_errors()\n",
    "e_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f1a36-c153-4341-9178-3b974ee7cf41",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The error data still shows some discrepancy in the vowel as last letter and the constant as last letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9f882-34bd-4416-98cd-b7ef06facefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga2.get_error_stats()\n",
    "e_df.groupby('tag').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabf34a-395d-4b09-b5cb-745c49e4fde2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model 3\n",
    "This model extends the simple model and uses first letter, the last letter, the last 2 letters as features for name categorization.  This model has a 84.4% accuracy if we use 3210 as the seed. We can also count the number of errors that are driven by unisex names. With Model 3 there are 24 errors that can be attributed to unisex names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f271d-f857-463b-83b9-fc615cbc83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga3 = GenderAnalysis3()\n",
    "ga3.train()\n",
    "\n",
    "print('devtest accuracy:', ga3.get_devtest_accuracy())\n",
    "print('ambiguous errors:',len(ga3.get_ambiguous_errors()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca3602-afb9-47ba-a554-4285c19ba46b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The feature list below identifies the features that have the biggest impact on the model. It should be noted that suffixLast2 features dominate the top features list and the first letter does not appear as a top 20 feature . Indicating that using 2 of the last characters is more deterministic of gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678085bf-cb22-4b16-bd30-3f92b20c3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga3.show_inform_feature(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0e570-a8f4-495e-8852-4323d42fab76",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The errors in name gender categorization are summarized in the following data frame. It is difficult to identify patterns at the individual name level so we will run some sample stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c80e2d-c2fa-4f3a-b62c-1f2f945967a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga3.get_errors()\n",
    "e_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01909bce-ca0b-4749-9970-6aa4738067ad",
   "metadata": {},
   "source": [
    "The error data analysis still shows two discrepancy in the vowel as last letter and the constant as last letter gender breakdown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a64970-3801-44e8-97a5-236d88b24199",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga3.get_error_stats()\n",
    "e_df.groupby('tag').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b16bbe-31ce-4622-99c9-ba0ba7ad948c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model 4\n",
    "\n",
    "This model extends the simple model and uses first letter, the last letter, the last 2 letters as features for name categorization. It also uses the length of the name and the vowel counts as features for the name. This model has a 84.2% accuracy if we use 3210 as the seed. We can also count the number of errors that are driven by unisex names. With Model 4 there are 22 errors that can be attributed to unisex names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a10ae-a7d7-470a-ad19-ddc1abdf1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4 = GenderAnalysis4()\n",
    "ga4.train()\n",
    "\n",
    "\n",
    "print('devtest accuracy:', ga4.get_devtest_accuracy())\n",
    "print('ambiguous errors:',len(ga4.get_ambiguous_errors()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9df12-44d6-4b12-b676-3c8ede0200a0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The feature list below identifies the features that have the biggest impact on the model. It should be noted that suffixLast2 features dominate the top features list and the first letter or the vowel related features do not appear as a top 20 feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b739cb-32d6-4b6c-9298-7bc24695e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4.show_inform_feature(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89981d3-520b-4eeb-8b35-7e16fbf48a4e",
   "metadata": {},
   "source": [
    "The errors in name gender categorization are summarized in the following data frame. It is difficult to identify patterns at the individual name level so we will run some sample stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ccaf9-34d2-46a9-983f-743cbd3658ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga4.get_errors()\n",
    "e_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf755093-9516-4f91-8d67-8c5f2f418a53",
   "metadata": {},
   "source": [
    "The error data analysis still shows two discrepancy in the vowel as last letter and the constant as last letter gender breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0a13f-653c-4616-be39-70e4befcfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df = ga3.get_error_stats()\n",
    "e_df.groupby('tag').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70572547-deba-403f-8b4c-2d1b0e26e421",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model Accuracy\n",
    "The accuracy for name categorization estimates seems to platau at roughly 85%. There appears to be some room to improve based on the treatment of vowels and consonants as the last letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cac622-168c-4512-b53b-cf1d4e7a158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lst = []\n",
    "result_lst.append(['ga1',ga1.get_devtest_accuracy(),len(ga1.get_errors()),len(ga1.get_ambiguous_errors()),ga1.get_test_accuracy()])\n",
    "result_lst.append(['ga2',ga2.get_devtest_accuracy(),len(ga2.get_errors()),len(ga2.get_ambiguous_errors()),ga2.get_test_accuracy()])\n",
    "result_lst.append(['ga3',ga3.get_devtest_accuracy(),len(ga3.get_errors()),len(ga3.get_ambiguous_errors()),ga3.get_test_accuracy()])\n",
    "result_lst.append(['ga4',ga4.get_devtest_accuracy(),len(ga4.get_errors()),len(ga4.get_ambiguous_errors()),ga4.get_test_accuracy()])\n",
    "\n",
    "#result_df = pd.DataFrame(result_lst)\n",
    "result_df = pd.DataFrame(result_lst, columns=['id','dt_accuracy','errors','ambiguous_errors','test_accuracy'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa9c9f-6551-4242-9ddd-4ffbd8e22ad9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### K-Fold Cross Validation\n",
    "Using the K-fold method for cross validation we can examine how widely the performance varies across different training sets. K-fold cross validation will help us Identify the most \"stable\" model on out of sample data.\n",
    "\n",
    "- First k fold produced the highest accuracy for each model\n",
    "- Sixth k fold produced the lowest accuracy for each model\n",
    "- Most of Model 1's results are within 1.5% of mean accuracy with the largest being 2.4%\n",
    "- Most of Model 2's results are within 2% of mean accuracy with the largest being 3.7%\n",
    "- Most of Model 3's results are within 2% of mean accuracy with the largest being 4.3%\n",
    "- Most of Model 4's results are within 1.25% of mean accuracy with the largest being 3.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db84c30-5f58-45c4-9d34-749cf2dcaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list\n",
    "lst = []\n",
    "\n",
    "# model 1\n",
    "dict = ga1.get_kfold().to_dict(orient='index')[0]\n",
    "dict.update({'id':'ga1'})\n",
    "lst.append(dict)\n",
    "\n",
    "# model 2\n",
    "dict = ga2.get_kfold().to_dict(orient='index')[0]\n",
    "dict.update({'id':'ga2'})\n",
    "lst.append(dict)\n",
    "\n",
    "# model 3\n",
    "dict = ga3.get_kfold().to_dict(orient='index')[0]\n",
    "dict.update({'id':'ga3'})\n",
    "lst.append(dict)\n",
    "\n",
    "# model 4\n",
    "dict = ga4.get_kfold().to_dict(orient='index')[0]\n",
    "dict.update({'id':'ga4'})\n",
    "lst.append(dict)\n",
    "\n",
    "# k folds dataframe\n",
    "df = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e339f-2ed6-4a70-97a3-394b3815e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns[pd.Series(df.columns).str.startswith('k_')])\n",
    "columns.remove('k_average')\n",
    "l_df = pd.melt(df, id_vars =['id'], value_vars = columns, var_name ='fold', value_name ='accuracy' )\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=l_df, \n",
    "    title='Model Validation',\n",
    "    y='accuracy',\n",
    "    color='id')\n",
    "\n",
    "# Show your work\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af49e5-27db-441c-a5b0-9cb382330366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary data\n",
    "pd.merge(left=result_df,right=df,left_on='id',right_on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219b1eb-f2d9-4bb9-a79e-7376bdf33159",
   "metadata": {},
   "source": [
    "From the analysis we can see that Model 3 and Model 4 both perform well on all accuracy metrics, compared to the other models. Model 4 appears to be the better of the two models on out of sample performance, as it has the highest testing data accuracy and best average k-fold cross validation accuracy. Model 4 also had a fairly consistent accuracy across all k fold training sets, indicating that we can be fairly confident that the score is accurate. However it should be noted that this number can fluctuate depending on the ramdom seed selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969dc00-cdd4-4899-a647-7c119e01cef3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Conclusion\n",
    "The difficulties associated with getting better accuracy in the gender classification names is impacted by the prevalence of unisex names. With 365 unisex names in the corpus it is common to see 24% to 28% of the errors are generated by unisex names that appear in corpus as both male and female names. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
